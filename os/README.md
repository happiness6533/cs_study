## 프로세스 vs 스레드

프로그램이란? 어떤 작업을 위해 실행할 수 있는 파일을 의미한다.



#### 프로세스(Process)

- 실행 중인 프로그램으로 디스크로부터 메모리에 적재되어 CPU의 할당을 받은 작업의 단위다.
- 운영체제로부터 시스템 자원을 할당받는다.

- 할당받는 시스템 자원
  - CPU 시간
  - 운영되기 위한 주소 공간
  - Code, Data, Stack, Heap의 구조로 되어있는 독립된 메모리 영역.

<img src="https://user-images.githubusercontent.com/33534771/77537773-fe37fb00-6ee1-11ea-8def-4dd11523b5e7.png" />

- 기본적으로 프로세스마다 최소 1개의 스레드를 갖는다.(메인 스레드)
- 프로세스는 각각 별도의 메모리 영역(주소 공간)을 할당받는다.  [Code, Data, Stack, Heap]
- 한 프로세스는 다른 프로세스의 변수나 자료구조에 접근할 수 없으며, 접근을 위해서는 IPC 통신이 필요하다.
  - Ex) 파이프, 파일, 소켓 등을 이용한 통신 방법 이용.



#### 프로세스 제어 블록(Process Control Block, PCB)

- 특정 프로세스에 대한 중요한 정보를 저장하고 있는 **커널 내의 자료구조**이다.
- OS는 프로세스를 관리하기 위해 프로세스의 생성과 동시에 고유한 PCB를 생성한다. 
- 프로세스는 CPU를 할당받아 작업을 처리하다가 프로세스 전환이 발생하면 진행하던 작업을 저장하고 CPU를 반환해야 한다. 이때 작업의 진행 상황을 모두 PCB에 저장한다. 그리고 다시 CPU를 할당받게 되면 PCB에 저장되었던 내용을 불러와 종료되었던 시점부터 다시 작업을 수행한다.

- PCB에 저장되는 정보
  - 프로세스 식별자(Process ID, PID) : 프로세스 식별 번호
  - 프로세스 상태 : new, ready, running, waiting, terminated 등의 상태를 저장
  - 프로그램 카운터(Program Counter, PC) : 프로세스가 다음에 실행할 명령어의 주소를 가리킨다.
  - CPU 레지스터
  - CPU 스케줄링 정보 : 프로세스의 우선순위, 스케줄 큐에 대한 포인터 등
  - 메모리 관리 정보 : 페이지 테이블 또는 세그먼트 테이블 등과 같은 정보를 포함한다.
  - 입출력 상태 정보 : 프로세스에 할당된 입출력 장치들과 열린 파일 목록
  - 어카운팅 정보 : 사용된 CPU 시간, 시간 제한, 계정 번호 등



#### 스레드(Thread)

- 프로세스의 실행 단위라고 할 수 있으며, 한 프로세스 내에서 동작되는 여러 실행 흐름으로 프로세스 내의 주소 공간이나 자원을 공유할 수 있다.

<img src="https://user-images.githubusercontent.com/33534771/77537866-232c6e00-6ee2-11ea-91dc-12dacf688276.png" />

- 스레드는 프로세스 내의 Code, Data, Heap 영역은 다른 스레드와 공유하고 Stack 영역을 따로 할당받는다.
- 여러 스레드는 한 프로세스 내의 Code, Data, Heap 영역을 공유하지만, 프로세스 간에는 메모리에 접근할 수 없다.
- 스레드는 별도의 레지스터와 스택을 갖고 있으며, 다른 영역을 공유한다. 따라서 한 스레드가 프로세스의 자원을 변경하면, 다른 스레드도 그 변경 결과를 즉시 확인할 수 있다.



`[요약]`

`프로세스` : 자신만의 고유 공간과 자원을 할당받아 사용하는 작업의 단위.

`스레드` : 프로세스 내에서 실행되는 흐름의 단위로, 다른 스레드와 프로세스의 자원과 공간을 공유하면서 사용.



## 멀티 프로세스 vs 멀티 스레드

#### 멀티 프로세스(Multi Process)

- 하나의 응용프로그램을 여러 개의 프로세스로 구성하여 각 프로세스가 하나의 작업을 처리하도록 하는 것.
- 장점
  - 여러 개의 자식 프로세스 중 하나에 문제가 발생하면 그 자식 프로세스만 죽는 것 이상으로 다른 영향이 확산되지 않는다. (안전성)
- 단점
  1. Context Switching에서의 오버헤드
     - 프로세스는 각 독립된 메모리 영역을 할당받았기 때문에 공유하는 메모리가 없다. 따라서 캐시 메모리 초기화 등의 무거운 작업이 진행되고 많은 시간이 소모되는 등의 오버헤드가 발생할 문제가 있다.
  2. 프로세스 간 통신 기법 IPC
     - 프로세스는 각 독립된 메모리 영역을 할당받았기 때문에 프로세스들 사이에서 변수나 자료구조를 공유할 수 없다. 따라서 IPC라는 방법을 사용해야 하며, 이는 어렵고 복잡한 통신 방법이다.



#### 멀티 스레드(Multi Thread)

- 하나의 응용 프로그램을 여러 개의 스레드로 구성하고 각 스레드가 하나의 작업을 처리하도록 하는 것.
- 윈도우, 리눅스 등 많은 OS들이 멀티 프로세싱을 지원하고 있지만, 멀티 스레딩을 기본으로 하고 있다.
- 웹 서버는 대표적인 멀티 스레드 응용 프로그램이다.
- 장점
  - 메모리 공간과 시스템 자원 소모가 줄어들게 된다.
  - 스레드 간 통신시, 전역 변수의 공간 또는 동적으로 할당된 공간인 Heap 영역을 이용해 데이터를 주고 받으므로 통신 방법이 간단하다.
  - Context switching 시, 캐시 메모리를 비울 필요가 없기 때문에 비용이 적고 더 빠르다.
  - 따라서 시스템의 처리량이 향상되고 자원 소모가 줄어들며, 자연스럽게 프로그램의 응답 시간이 단축된다.

- 단점
  - 서로 다른 스레드가 Data, Heap 영역 등을 공유하기 때문에 어떤 스레드가 다른 스레드에서 사용중인 변수나 자료구조에 접근하여 엉뚱한 값을 읽어오거나 수정할 수 있다. 즉, 자원 공유의 문제가 발생한다.(동기화)
  - 하나의 스레드에 문제가 생기면 전체 프로세스가 영향을 받는다.
  - 주의 깊은 설계가 필요하며, 디버깅이 까다롭다



### 멀티 스레드 vs 멀티 프로세스

멀티 스레드는 멀티 프로세스보다 적은 메모리 공간을 차지하고 Context Switching이 빠르다는 장점이 있지만, 오류로 인해 하나의 스레드가 종료되면 전체 스레드가 종료될 수 있다는 점과 동기화 문제를 가지고 있다. 

반면, 멀티 프로세싱 방식은 하나의 프로세스가 죽더라도 다른 프로세스에는 영향을 끼치지 않고 정상적으로 수행된다는 장점이 있지만, 멀티 스레드보다 많은 메모리 공간과 CPU 시간을 차지한다는 단점이 존재한다. 

이 두 가지는 동시에 여러 작업을 수행한다는 점에서 같지만 적용해야 하는 시스템에 따라 적합/부적합이 구분된다. 따라서 대상 시스템의 특징에 따라 적합한 동작 방식을 선택하고 적용해야 한다



**[자주 나오는 질문]**

**Q. 스택을 스레드마다 독립적으로 할당하는 이유는 뭘까?**

스택은 함수 호출시 전달되는 인자, 복귀 주소값 및 함수 내에서 선언하는 변수 등을 저장하기 위해 사용되는 메모리 공간.

스택 메모리 공간이 독립적이라는 것은 독립적인 함수 호출이 가능함을 의미하고 이는 독립적인 실행 흐름이 추가된다는 것이다. 따라서 스레드의 정의에 따라 독립적인 실행 흐름을 추가하기 위한 최소 조건으로 독립된 스택을 할당하는 것이다.



**Q. PC 레지스터를 스레드마다 독립적으로 할당하는 이유는 뭘까?**

PC 값은 스레드가 명령어의 어디까지 수행했는지를 나타내게 된다. 스레드는 CPU를 할당받았다가 스케줄러에 의해 다시 선점당한다. 그렇기 때문에 명령어가 연속적으로 수행되지 못하고 어느 부분까지 수행했는지 기억할 필요가 있다. 따라서 PC 레지스터를 독립적으로 할당한다.



`[요약]`

**Q. 멀티 프로세스 대신 멀티 스레드를 사용하는 이유는?**

<img src="https://user-images.githubusercontent.com/33534771/77537949-41926980-6ee2-11ea-90eb-569dc64faed5.png" />

- 프로그램을 여러 개 키는 것보다 하나의 프로그램 안에서 여러 작업을 해결하는 것이 더욱 효율적이기 때문이다.
- **프로세스를 생성하여 자원을 할당하는 시스템 콜이 줄어들어 자원을 효율적으로 관리할 수 있다.**
- Context Switching시, 캐시 메모리를 비울 필요가 없기 때문에 비용이 적고 더 빠르다.-> 스레드는 Stack 영역만 초기화하면 되기 때문이다.
- 스레드는 프로세스 내의 메모리를 공유하기 때문에 데이터 전달이 간단하므로 IPC에 비해 비용이 적고 더 빠르다. -> 스레드는 프로세스의 Stack 영역을 제외한 모든 메모리를 공유하기 때문이다.



+Alpha

**Q. Context Switching이란?**

- CPU는 한번에 하나의 프로세스만 처리할 수 있다.
- 여러 프로세스를 처리해야 하는 상황에서 현재 진행중인 Task(프로세스, 스레드)의 상태를 PCB에 저장하고 다음에 진행할 Task의 상태값을 읽어 적용하는 과정을 말한다. (**다른 프로세스에게 CPU를 할당해 작업을 수행하는 과정을 말한다.**)
- 과정
  - Task의 대부분 정보는 Register에 저장되고 PCB로 관리된다.
  - 현재 실행하고 있는 Task의 PCB 정보를 저장한다.
  - 다음 실행할 Task의 PCB 정보를 읽어 Register에 적재하고 CPU가 이전에 진행했던 과정을 연속적으로 수행할 수 있다.
- Context Switching은 많은 비용이 소모된다.
  - Cache 초기화
  - Memory mapping 초기화
  - 커널은 항상 실행되어야 한다.
- Context Switching의 비용은 프로세스가 스레드보다 더 많이 든다.
- 이유 : 스레드는 Stack 영역을 제외한 모든 메모리를 공유하기 때문에 Context Switching 발생시 Stack 영역만 변경을 진행하면 되기 때문이다.





### Thread-safe

- 멀티스레드 환경에서 여러 스레드가 동시에 하나의 객체 및 변수(공유 자원)에 접근할 때, 의도한 대로 동작하는 것을 말한다.
- 이러한 상황을 "Thread-safe 하다"라고 표현한다.
- Thread-safe 하게 구현하기
  - 이를 위해서는 공유 자원에 접근하는 임계영역(critical section)을 동기화 기법으로 제어해줘야 한다. 이를 '상호배제'라고 한다.
  - 동기화 기법으로는 뮤텍스나 세마포어가 존재하며, 다른 페이지에서 확인할 수 있다.



- Reentrant
  - `재진입성`이라는 의미로, 어떤 함수가 Reentrant하다는 것은 여러 스레드가 동시에 접근해도 언제나 같은 실행 결과를 보장한다는 의미이다.
  - 이를 만족하기 위해서 해당 서브루틴에서는 공유자원을 사용하지 않으면 된다.
    - 예를 들어, 정적(전역) 변수를 사용하거나 반환하면 안되고 호출 시 제공된 매개변수만으로 동작해야 한다.
  - 따라서, Reentrant하다면 Thread-safe하지만 그 역은 성립하지 않는다.


  ## 동기화 문제

- 동기화 : 한정적인 시스템 자원에 여러 스레드가 동시에 접근해서 사용하면 문제가 발생할 수 있다. 이 문제를 방지하기 위해 여러 스레드에게 하나의 자원에 대한 처리 권한을 주거나 순서를 조정하는 기법이다.



**스레드 동기화**

1. 실행 순서의 동기화 : 스레드의 실행 순서를 정의하고, 이 순서를 반드시 따르도록 하는 것.
2. 메모리 접근에 대한 동기화
   - 메모리 접근에 있어서 동시 접근을 막는 것.
   - 실행의 순서가 중요한 것이 아니라 한 순간에 하나의 스레드만 해당 자원에 접근하도록 하는 것.



**동기화 기법**

- 유저 모드의 동기화
  - 커널의 힘을 빌리지 않는 동기화 기법(커널의 코드가 실행되지 않음.)
  - 성능상 이점이 있으나 기능상의 제한점이 존재.
  - 임계 구역 기반의 동기화, 인터락 함수 기반의 동기화.
- 커널 모드의 동기화
  - 커널에서 제공하는 동기화 기능을 이용하는 방법.
  - 커널 모드로의 변경이 필요하고 이는 성능 저하로 이어진다. 그러나 다양한 기능을 활용할 수 있다.
  - 세마포어, 뮤텍스, 모니터 등등.

`[유저모드의 동기화]`

1. 임계 구역 기반의 동기화.

- 열쇠를 얻은 프로세스만 임계 구역에 들어갈 수 있다. 즉, 한번에 하나의 스레드만이 접근 가능하다.
- 임계 구역 진입을 위해 크리티컬 섹션 오브젝트를 얻는다.
- 다른 스레드가 열쇠를 가지고 있을 시에는 반환할 때까지 블로킹된다. 열쇠가 반환되면 블로킹 상태에서 빠져나와 열쇠를 얻고 임계 구역에 접근한다.



2. 인터락 함수 기반의 동기화

- 함수 내부적으로 한 순간에 하나의 스레드에 의해서만 실행되도록 동기화된다.
- 임계 구역 기반의 동기화도 내부적으로 인터락 함수를 기반으로 구현된다.
- 유저 모드 기반으로 동작해서 속도가 빠르다.



`[커널모드의 동기화]`

1. 세마포어(Semaphore)

- 공유된 자원의 데이터를 여러 프로세스, 스레드가 접근하는 것을 막는 것이다.
- 동시에 접근할 수 있는 '허용 가능한 갯수'를 가지고 있는 Counter. (공유자원에 접근할 수 있는 스레드 혹은 프로세스의 수를 나타내는 값. -> 공통으로 관리하는 하나의 값)
- Ex)
  - 화장실을 예로 들어보자. 세마포어는 1개 이상의 열쇠라고 할 수 있다. 화장실 칸이 4개이고 열쇠가 4개라면, 4명까지는 대기없이 바로 사용할 수 있다. 그 다음부터는 대기를 해야 한다. 이것이 바로 세마포어이다.
- 세마포어 Counter의 갯수에 따라 다음과 같이 나뉜다.
  - 1개 : Binary Semaphore(뮤텍스와 같다.)
  - 2개 이상 : Counting Semaphore
- 세마포어는 소유할 수 없다.
  - 세마포어를 소유하지 않은 스레드가 세마포어를 해제할 수 있는 문제가 발생한다.



2. 뮤텍스(Mutal Exclusion)

- 공유된 자원의 데이터를 여러 프로세스, 스레드가 접근하는 것을 막는 것이다.
- 임계 구역을 가진 스레드들의 Running time이 서로 겹치지 않게 각각 단독으로 실행되게 하는 기술이다.
- **뮤텍스 객체를 두 스레드가 동시에 사용할 수 없다.**
- 일종의 Locking 매커니즘으로 공유 자원에 대한 접근을 조율하기 위해 locking과 unlocking을 사용한다.
- Lock에 대한 소유권이 있으며 Lock을 가지고 있을 경우에만 공유 자원에 접근할 수 있고, Lock을 가진 사람만 반납할 수 있다.
- 뮤텍스는 무조건 1개의 열쇠만 가질 수 있다. 열쇠를 가진 사람만이 화장실에 갈 수 있고, 다음 사람이 화장실에 가기 위해서는 앞 사람이 열쇠를 반납해야 한다.



3. 모니터(Monitor)

- Mutex(Lock)와 Condition Variables를 가지고 있는 Synchronization 매커니즘이다.



뮤텍스와 모니터는 상호 배제를 함으로써 임계 구역에 하나의 쓰레드만 들어갈 수 있다.

반면, 세마포어는 하나의 쓰레드만 들어가거나 혹은 여러개의 쓰레드가 들어가게 할 수도 있다.



#### Q. 임계영역이란?

- 둘 이상의 스레드가 동시에 접근해서는 안되는 공유 자원을 접근하는 코드의 일부를 말한다.
- 임계 영역에서 동기화를 진행하지 못하면 치명적인 문제가 발생.
- 따라서 임계 구역 문제를 해결하기 위해서는 3가지 필수 조건이 있다.
  1. 상호 배제(Mutual exclusion) : 프로세스 P1이 공유 자원을 접근하는 임계 구역 코드를 수행하고 있으면 다른 프로세스들은 공유 자원을 접근하는 임계 구역 코드를 수행할 수 없다. 즉, 한 순간에 하나의 스레드만이 실행될 수 있다.
  2. 진행(Progress) : 임계 구역에서 실행중인 프로세스가 없고 별도의 동작이 없는 프로세스들만 임계 구역 진입 후보로서 참여될 수 있다.
  3. 한정된 대기(Bounded Waiting) : P1이 임계 구역에 진입 신청 후부터 받아들여질때까지, 다른 프로세스들이 임계 구역에 진입하는 횟수는 제한이 있어야 한다.



**Q. 뮤텍스와 모니터의 차이는?**

- 뮤텍스는 다른 프로세스나 스레드 간에 동기화를 위해 사용한다.
- 모니터는 하나의 프로세스내에서 다른 스레드 간에 동기화할 때 사용한다.
- 뮤텍스는 운영체제 커널에 의해 제공된다.
  - 무겁고 느리다.
- 모니터는 프레임워크나 라이브러리 그 자체에서 제공된다.
  - 가볍고 빠르다.



**Q. 세마포어와 모니터의 차이는?**

- 자바에서는 모니터를 모든 객체에게 기본적으로 제공하지만 C에서는 사용할 수 없음.
- 세마포어는 카운터라는 변수값으로 프로그래머가 상호 배제나 정렬의 목적으로 사용시 매번 값을 따로 지정해줘야 하는 등 조금 번거롭다.
- 반면, 모니터는 이러한 일들이 캡슐화되어 있어서 개발자는 카운터 값을 0 또는 1으로 주어야 하는 고민을 할 필요가 없이 synchronized, wait(), notify() 등의 키워드를 이용해 좀 더 편하게 동기화할 수 있다.

**Q. 세마포어와 뮤텍스의 차이는?**

- 세마포어는 뮤텍스가 될 수 있지만, 뮤텍스는 세마포어가 될 수 없다.
- 세마포어는 소유할 수 없으며, 뮤텍스는 소유할 수 있고 소유주가 그 책임을 진다.
- 뮤텍스의 경우 뮤텍스를 소유하고 있는 스레드가 이 뮤텍스를 해제할 수 있다. 하지만 세마포어는 소유하지 않고 있는 다른 스레드가 세마포어를 해제할 수 있다.
- 뮤텍스는 동기화 대상이 1개일 때 사용하고 세마포어는 동기화 대상이 여러 개일때 사용한다.



**[Toilet Problem]**

동시성 프로그래밍의 가장 큰 숙제는 '공유자원 관리'이다. 공유 자원을 안전하게 관리하기 위해서는 상호배제를 달성하는 기법이 필요하며, 뮤텍스와 세마포어가 이를 위해 고안된 기법이다. 이 둘은 서로 다른 방식으로 상호배제를 달성한다.

이 둘은 화장실 문제에 적용하여 풀어낼 것이다.

1) 뮤텍스

뮤텍스는 화장실이 하나뿐인 식당과 비슷하다. 화장실에 가기 위해서 카운터에서 열쇠를 받아가야 한다.

내가 화장실을 가려고 하는데 카운터에 키가 있으면 화장실에 사람이 없다는 의미이고 나는 열쇠를 가지고 화장실에 갈 수 있다.

![img](https://cdn-images-1.medium.com/max/1600/1*6JKj81oYsxQlDhjAlMXQjg.png)



화장실에 가고 싶은 다른 사람이 있다. 이 사람은 급하지만 열쇠가 없기 때문에 화장실에 갈 수 없고 기다려야 한다. 내가 용무를 끝내 나올 때까지 카운터에서 기다려야 한다. 또 다른 사람도 화장실에 가고 싶어 카운터에서 대기한다.

![img](https://cdn-images-1.medium.com/max/1600/1*CgUE8ByDUKnVkkrEbMPwCQ.png)

나는 화장실에서 나와 카운터에 키를 올려놓는다. 이제 기다리던 사람들 중 맨 앞에 있던 사람은 키를 받을 수 있고 화장실에 갈 수 있다.

![img](https://cdn-images-1.medium.com/max/1600/1*dIIfI3ezb3Gt2YH1uWhauQ.png)

이게 뮤텍스가 동작하는 방식이다. 

화장실을 이용하는 사람 : 프로세스 혹은 스레드

화장실 : 공유 자원

화장실 키 : 공유 자원에 접근하기 위해 필요한 어떤 오브젝트.

![img](https://cdn-images-1.medium.com/max/1600/1*CdLr52i_BZjnEf3uWZyRVQ.png)

즉, 뮤텍스는 Key에 해당하는 어떤 오브젝트가 있으며 이 오브젝트를 소유한 프로세스나 스레드만이 공유 자원에 접근할 수 있다.



2) 세마포어

화장실을 좀 더 쉽게 이용할 수 있는 레스토랑으로 생각하면 된다. 레스토랑의 화장실은 여러 개의 칸이 있다. 그리고 화장실 입구에는 현재 화장실의 빈칸 갯수를 보여주는 전광판이 있다.

![img](https://cdn-images-1.medium.com/max/1600/1*ZJXrQu8rFhSQxW6LVAI-GA.png)

나는 화장실에 가고 싶고, 입구에서 빈 칸의 갯수를 확인하고 1개 이상이라면 빈칸의 갯수를 하나 뺀 다음 화장실에 입장해야 한다. 그리고 나올 때, 빈칸의 갯수를 복구하기 위해 하나를 더해준다.

![img](https://cdn-images-1.medium.com/max/1600/1*lFNABipdkdtxFvW9UZmCaw.png)

모든 칸에 사람이 들어갔을 경우, 빈칸의 갯수는 0이되며 이때 화장실에 들어가고자 하는 사람이 있다면 빈칸의 갯수가 1로 바뀔때까지 기다려야 한다.

![img](https://cdn-images-1.medium.com/max/1600/1*wP9yqG6QBuS7A8i_kKTyRA.png)

이용을 마친 사람들은 나오면서 빈칸의 갯수를 1씩 더한다. 그리고 기다리던 사람은 이 숫자에서 다시 1을 뺀 다음 화장실로 입장한다.

![img](https://cdn-images-1.medium.com/max/1600/1*36aMopAPHO3e80YYADmY6w.png)

세마포어는 공통으로 관리하는 하나의 값을 이용해 상호배제를 달성한다.

화장실을 이용하는 사람 : 프로세스 혹은 스레드

화장실 : 공유 자원

화장실 빈칸의 갯수 : 현재 공유 자원에 접근할 수 있는 스레드, 프로세스의 갯수를 나타냄.



`[요약]`

뮤텍스 : 한 스레드, 프로세스에 의해 소유될 수 있는 Key를 기반으로 한 상호배제 기법

세마포어 : 현재 공유자원에 접근할 수 있는 스레드, 프로세스의 수를 나타내는 값을 두어 상호배제를 달성하는 기법

**뮤텍스와 세마포어의 목적은 특정 동기화 대상이 이미 특정 스레드나 프로세스에 의해 사용중일 경우, 다른 스레드가 해당 동기화 대상에 접근하는 것을 제한하는 것으로 동일하지만, 관리하는 동기화 대상이 몇개인가에 따라 차이가 생긴다.**



두 기법 모두 완벽하지는 않다. 이 기법들을 사용하더라도 데이터 무결성을 보장할 수 없으며 데드락이 발생할 수도 있다. 하지만 상호배제를 위한 기본적인 기법이며 여기에 좀 더 복잡한 매커니즘을 적용해 꽤나 우아하게 동작하는 프로그램을 짤 수 있다고 한다.



> 참고
>
> - [뮤텍스(Mutex)와 세마포어(Semaphore)의 차이](https://worthpreading.tistory.com/90)


**Q. Context Switching이란?**

- CPU는 한번에 하나의 프로세스만 처리할 수 있다.
- 여러 프로세스를 처리해야 하는 상황에서 현재 진행중인 Task(프로세스, 스레드)의 상태를 PCB에 저장하고 다음에 진행할 Task의 상태값을 읽어 적용하는 과정을 말한다. (**다른 프로세스에게 CPU를 할당해 작업을 수행하는 과정을 말한다.**)
- 과정
  - Task의 대부분 정보는 Register에 저장되고 PCB로 관리된다.
  - 현재 실행하고 있는 Task의 PCB 정보를 저장한다.
  - 다음 실행할 Task의 PCB 정보를 읽어 Register에 적재하고 CPU가 이전에 진행했던 과정을 연속적으로 수행할 수 있다.
- Context Switching은 많은 비용이 소모된다.
  - Cache 초기화
  - Memory mapping 초기화
  - 커널은 항상 실행되어야 한다.
- Context Switching의 비용은 프로세스가 스레드보다 더 많이 든다.
- 이유 : 스레드는 Stack 영역을 제외한 모든 메모리를 공유하기 때문에 Context Switching 발생시 Stack 영역만 변경을 진행하면 되기 때문이다.


### 인터럽트(Interrupt)

- 하드웨어 장치가 CPU에게 어떤 사실을 알려주거나 CPU의 서비스를 요청해야 할 경우, CPU 내에 있는 인터럽트 라인을 세팅하여 인터럽트를 발생시킨다. (프로그램이 명령을 수행하기 위해서는 CPU를 할당받아야 함)
- CPU는 매번 프로그램 카운터가 가리고 있는 곳의 명령을 수행한 뒤, 다음 명령을 수행하기 직전에 인터럽트 라인이 세팅되었는지 체크한다.
- 이를 통해 인터럽트가 발생했으면 CPU는 현재 수행 중이던 프로세스를 멈추고 운영 체제의 인터럽트 처리 루틴으로 이동하여 인터럽트 처리를 수행한다. 



#### 인터럽트의 종류

1. 하드웨어 인터럽트(일반적인 인터럽트)
   - 하드웨어 컨트롤러가 CPU의 서비스를 요청하기 위해 발생시키는 인터럽트

<img src="https://k.kakaocdn.net/dn/bwovTQ/btqvBp24GS1/AxuTAkEaZaQwobodqeEfQk/img.png" alt="img" style="zoom:50%;" />

<center>하드웨어 인터럽트 발생 과정</center>

2. 소프트웨어 인터럽트(Trap:트랩)

1) 예외 상황(Exception) 

- 프로그램이 허용되지 않은 연산을 수행하려고 할 때, 자동적으로 발생한다. 운영체제는 예외 상황이 발생했을 때, CPU의 제어권을 획득해 이 상황에 대한 조치를 취한다.
- ex) 0으로 나누는 연산, 자신의 주소 공간을 넘어서는 메모리 참조 등
- 예외 상황에 대한 처리 루틴을 자신의 코드 영역에 가지고 있음

2) 시스템 콜(System Call) 

- 사용자 프로세스가 운영체제의 서비스를 요청하기 위해 커널의 함수를 호출하는 것이다. 
- 사용자 프로세스가 직접 특권 명령을 수행할 수 없으므로 특권 명령을 수행하려 할 때, 시스템 콜을 사용한다. 

<img src="https://k.kakaocdn.net/dn/QnqLh/btqvABC7Ea2/sflPVirxNdWXOiQkc8CQz1/img.png" alt="img" style="zoom:50%;" />

<center>소프트웨어 인터럽트 발생 과정</center>

시스템 콜이나 예외 상황은 모두 사용자 프로세스로부터 CPU의 제어권이 운영 체제에게 이양되어 처리되는데 이 과정에 인터럽트 라인을 세팅하여 인터럽트를 발생시킨 후 제어권이 넘어가게 되므로 이들도 넓은 의미에서는 인터럽트의 범주에 포함시킨다. **단지 인터럽트를 발생시키는 주체가 하드웨어 장치가 아닌 소프트웨어이므로 이들을 소프트웨어 인터럽트라고 부른다.**





#### 인터럽트 발생 처리 과정

A 프로그램이 CPU를 할당받고 명령을 수행하고 있는데 인터럽트가 발생하면 A는 현재 수행중인 명령의 위치를 저장해놓는다. 그 후, 운영 체제 내부 코드인 인터럽트 처리 루틴으로 넘어가서 인터럽트 처리를 하고 다시 돌아와 A의 이전 작업 지점부터 수행을 계속 이어나가게 된다.



`그렇다면, 인터럽트가 발생했을 때 수행중이던 프로세스의 정보는 어디에 저장될까?`

-> 진행 중이던 A 프로세스의 정보는 프로세스 제어 블록(PCB: Process Control Block)에 저장한다. 그리고 인터럽트 처리를 모두 마치면 프로그램 A의 PCB에 저장된 주소를 복원시켜 원래 수행하던 일을 재개하게 된다. 



- 인터럽트 벡터(Interrupt Vector)
  - 여러가지 인터럽트에 대해 해당 인터럽트 발생시 처리해야 할 루틴의 주소를 보관하고 있는 테이블.
  - 일종의 함수를 가리키는 포인터

- 인터럽트 핸들러(Interrupt Handler)
  - 실제 인터럽트를 처리하기 위한 루틴으로 인터럽트 서비스 루틴이라고도 한다.
  - 운영체제 코드 부분에는 각종 인터럽트 별로 처리해야 할 내용이 이미 프로그램되어 있으며, 이 부분을 인터럽트 서비스 루틴 또는 인터럽트 핸들러라고 한다.

예를 들어, 입출력 관련 인터럽트가 발생한 경우, CPU는 인터럽트 라인을 통해 발생한 인터럽트를 확인한다. 인터럽트 벡터를 통해 해당 인터럽트 발생시 처리해야 할 루틴의 메모리 주소를 알아낸다. 주소를 통해 실제 수행되어야 할 코드가 담겨있는 루틴을 찾아가 상황에 맞는 처리를 진행한다.



### 참고

- [#3 인터럽트의 원리 - 운영체제와 정보기술의 원리](https://real-dongsoo7.tistory.com/m/93?category=784608)
- [규글님 Github](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Operation%20System/Interrupt.md)





### 시스템 콜(System Call)

먼저, 커널 모드와 사용자 모드에 대해서 알아보자.

1) 커널 모드

프로그램 카운터가 운영체제가 존재하는 부분을 가리키고 있다면, 현재 운영체제의 코드를 수행 중이며 CPU가 커널 모드에서 수행 중이라고 한다.

2) 사용자 모드

프로그램 카운터가 사용자 프로그램이 존재하는 메모리 위치를 가리킬 경우, 사용자 프로그램을 수행 중이며 CPU가 사용자 모드에서 수행 중이라고 한다.

- 일반 명령 : 메모리에서 자료를 읽어와서 CPU에서 계산하고 결과를 메모리에 쓰는 일련의 명령들. 모든 프로그램이 수행할 수 있음. (사용자 모드)
- 특권 명령 : 보안이 필요한 명령으로 입출력 장치, 타이머 등 각종 장치를 접근하는 명령.(커널 모드)
- CPU 내에 모드 비트를 두어 두 명령을 수행한다.

- 사용자 프로그램이 디스크의 파일을 접근하거나, 화면에 결과를 출력하는 등의 작업이 필요한 경우가 있다. 하지만, 이러한 작업은 특권 명령의 수행을 필요로 한다. 
- 이와 같은 경우, 사용자 프로그램은 스스로 특권 명령을 수행할 수 없으므로 운영체제에게 특권 명령의 대행을 요청한다. 이러한 서비스 요청은 시스템 콜이라고 부른다. (즉, 특권 명령의 대행을 요청하여 사용자 프로그램이 커널 영역의 기능을 수행하게 해준다.)



**디스크에서 자료를 읽어오는 시스템 콜이라고 가정!**

1. 사용자 프로그램이 시스템 콜을 하게 되면 운영체제는 자신의 커널 영역에 정의된 시스템 콜 처리 코드를 수행한다.
2. CPU가 컨트롤 레지스터를 세팅해 디스크 컨트롤러에게 데이터를 읽어오라고 명령한다.
3. 디스크 컨트롤러는 디스크로부터 데이터를 읽어와서 자신의 로컬 버퍼에 저장한다.
4. 작업이 완료되면 디스크 컨트롤러가 CPU에게 인터럽트를 발생시켜 입출력 작업이 완료되었음을 통지한다.



통상적으로 시스템 콜은 여러 종류의 기능으로 나뉘어져 있다. 각 시스템 콜에는 번호가 할당되고 시스템 콜 인터페이스는 이러한 번호에 따라 인덱스되는 테이블을 유지한다. 아래 그림은 open() 시스템 콜을 호출했을 때, 운영체제에서 어떻게 처리되는지를 보여준다.

![img](https://t1.daumcdn.net/cfile/tistory/25333241535CCEE810)



필요한 기능이나 시스템 환경에 따라 시스템 콜이 발생할 때, 좀 더 많은 정보가 필요할 수도 있다. 그러한 정보가 담긴 매개변수를 운영체제에 전달하기 위해서는 대략 3가지 정도의 방법이 있다.

1) 매개변수를 CPU 레지스터 내에 전달한다. 이 경우에 매개변수의 갯수가 CPU 내의 레지스터 갯수보다 많을 수 있다.

2) 위와 같은 경우에 매개변수를 메모리에 저장하고 **메모리의 주소가 레지스터에 전달**된다. (아래 그림 참고)

3) 매개변수는 프로그램에 의해 **스택으로 전달**될 수도 있다.



![img](https://t1.daumcdn.net/cfile/tistory/27118142535CCF060A)



2,3번은 전달되는 **매개변수의 갯수나 길이에 제한이 없기 때문에** 몇몇 운영체제에서 선호하는 방식이다.



### 시스템 콜의 유형

5가지의 범주로 나눌 수 있다.

1. 프로세스 제어 : 프로세스 특권 모드를 사용해 직접적으로 프로세스 제어가 가능
2. 파일 조작 : 파일을 생성하거나 삭제, 관리 등
3. 장치 관리 : 장치 요구 및 장치 해제, 읽기, 쓰기, 재배치 등
4. 정보 유지 : 시간과 날짜의 설정과 획득, 시스템 자료의 설정과 획득
5. 통신 : 통신 연결의 생성 및 제거, 메시지의 송수신, 상태 정보 전달 등



### 참고

- [운영체제 04 : 시스템 콜](https://luckyyowu.tistory.com/133)
- [시스템 인터럽트, 시스템 콜](https://luckyyowu.tistory.com/2)





### 교착 상태(DeadLock)

- 한정된 자원을 여러 곳에서 사용하려고 할 때, 발생하는 문제이다.
- 즉, 프로세스가 자원을 얻지 못해서 다음 처리를 하지 못하는 상태이다.


![img](https://user-images.githubusercontent.com/33534771/87002992-c4230880-c1f5-11ea-8e0e-0bddc09e3f4a.png)

프로세스 1과 프로세스2가 모두 자원 1, 자원 2를 얻어야 한다고 가정해보자.

t1 : 프로세스 1이 자원 1을 얻음 / 프로세스 2가 자원 2를 얻음

t2 : 프로세스 1은 자원 2를 기다림 / 프로세스 2는 자원 1을 기다림



이처럼 현재 서로 원하는 자원이 상대방에게 할당되어 있어서 두 프로세스는 무한정 wait 상태에 빠지게 된다. -> 이러한 상황을 **DeadLock** 이라고 부른다.



**[주로 발생하는 경우]**

- 멀티 프로그래밍 환경에서 한정된 자원을 얻기 위해 서로 경쟁하는 상황 발생
- 한 프로세스가 자원을 요청했을 때, 동시에 그 자원을 사용할 수 없는 상황이 발생할 수 있음. 읻대 프로세스는 대기 상태로 들어감
- 대기 상태로 들어간 프로세스들이 실행 상태로 변경될 수 없을 때, '교착 상태' 발생



**[교착 상태 발생조건]**

- 4가지 조건이 동시에 성립할 때, 발생한다
- 4가지 조건 중 하나라도 성립하지 않는다면 교착 상태를 해결할 수 있다.



1) 상호 배제(Mutual Exclusion)

- 자원은 한 번에 한 프로세스만이 사용할 수 있다.

2) 점유 대기(Hold and Wait)

- 최소한 하나의 자원을 점유하고 있으면서 다른 프로세스에 할당되어 사용하고 있는 자원을 추가로 점유하기 위해 대기하는 프로세스가 있어야 한다.

3) 비선점 (No Preemption)

- 다른 프로세스에 할당된 자원은 사용이 끝나서 반납할 때까지 강제로 빼앗을 수 없다.

4) 순환 대기 (Circular Wait)

- 프로세스의 집합 {P0, P1, ..., Pn}에서 0은 1이 점유한 자원을 대기하고 1은 2가 점유한 자원을 대기하고 Pn은 P0이 점유한 자원을 요구해야 한다.
- 이처럼 프로세스의 집합에서 순환 형태로 자원을 대기하고 있어야 한다.



### 교착 상태 처리

아래와 같은 방법이 존재한다.



**[교착 상태 예방]**

- 교착 상태 발생 조건 중 하나를 제거함으로써 해결하는 방법
- 자원의 낭비가 심하다는 단점이 존재한다.

1. 상호 배제 부정
   여러 프로세스가 공유 자원을 사용하도록 한다.
2. 점유 대기 부정
   프로세스가 실행되기 전 필요한 모든 자원을 할당한다.
3. 비선점 부정
   자원 점유 중인 프로세스가 다른 자원을 요구할 때, 점유 중인 자원을 반납하고 요구한 자원을 사용하기 위해 기다리게 한다.
4. 순환 대기 부정
   자원에 고유한 번호를 할당하고, 번호 순서대로로 자원을 요구하도록 한다.



**[교착 상태 회피]**

- 교착 상태가 발생하면 피해나가는 방법
- 은행원 알고리즘이라고 한다.

- 다익스트라가 제안한 방법으로 은행에서 모든 고객의 요구가 충족되도록 현금을 할당하는데서 유래된 기법이다. 



프로세스가 자원을 요구할 때, 시스템은 자원을 할당한 후에도 안정 상태로 남아있게 되는지를 검사하여 교착 상태를 회피하는 기법이다. 

안정 상태에 있으면 자원을 할당하고 그렇지 않으면 다른 프로세스들이 자원을 해제할 때까지 대기한다.



![img](https://user-images.githubusercontent.com/33534771/87003104-f6346a80-c1f5-11ea-84f3-d048f1cec0ea.png)



[교착 상태 탐지]

- 자원 할당 그래프를 통해 교착 상태를 탐지할 수 있다.

![img](https://user-images.githubusercontent.com/33534771/87003146-0e0bee80-c1f6-11ea-8d99-d19c46e52324.png)

- 프로세스 Pi -> 자원 Rj : 프로세스 P가 자원 R을 요청하는 것으로 현재 이 자원을 기다리는 상태
- 자원 Rj -> 프로세스 Pi : 자원 R이 프로세스 P에 할당된 것을 의미한다.
- 자원을 요청할 때마다 탐지 알고리즘을 실행하므로 오버헤드가 발생한다.



[교착 상태 회복]

- 교착 상태를 일으킨 프로세스를 종료하거나 할당된 자원을 해제함으로써 회복하는 것을 의미한다.

1. 프로세스를 종료하는 방법
   - 교착 상태의 프로세스를 모두 중지
   - 교착 상태가 제거될 때까지 한 프로세스씩 중지
2. 자원을 선점하는 방법
   - 교착 상태의 프로세스가 점유하고 있는 자원을 선점하여 다른 프로세스에게 할당하며, 해당 프로세스를 일시 정지시키는 방법
   - 우선순위가 낮은 프로세스, 수행된 횟수가 적은 프로세스 등을 위주로 프로세스의 자원을 선점한다.



### 주요 질문

- 교착상태가 무엇이고, 발생 조건에 대해 설명해주세요.
- 회피 기법인 은행원 알고리즘이 대해 설명해주세요.
- 기아 상태를 설명하는 '식사하는 철학자 문제'에 대해 설명해주세요.

-> 교착 상태 해결책

1. n명이 앉을 수 있는 테이블에서 철학자 n-1명만을 앉게 한다.
2. 한 철학자가 젓가락 두 개를 모두 집을 수 있는 상황에서만 젓가락을 집도록 허용한다.
3. 누군가는 왼쪽 젓가락을 먼저 집지 않고 오른쪽 젓가락을 먼저 집도록 허용한다.



### Reference
- [규글님 DeadLock](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Operation%20System/DeadLock.md)





### CPU 스케줄링

CPU가 하나의 프로세스 작업이 끝나면 다음 프로세스 작업을 수행해야 한다. 이때 어떤 프로세스를 다음에 처리할 지 선택하는 알고리즘을 CPU Scheduling 알고리즘이라고 한다. 따라서 상황에 맞게 CPU를 어떤 프로세스에 배정하여 효율적으로 처리하는가가 관건이다.



### Preemptive vs Non-Preemptive

1) Preemptive(선점)

- 프로세스가 CPU를 점유하고 있는 동안 I/O나 인터럽트가 발생하지 않았음에도 다른 프로세스가 해당 CPU를 강제로 점유할 수 있다. 
- 즉, 프로세스가 정상적으로 수행중인 동안 다른 프로세스가 CPU를 강제로 점유하여 실행할 수 있다.



2) Non-Preemptive(비선점)

- 한 프로세스가 CPU를 점유했다면 I/O나 인터럽트 발생 또는 프로세스가 종료될 때까지 다른 프로세스가 CPU를 점유하지 못하는 것이다. 





### 선점형 스케줄링

1) SRT(Shortest Remaining Time) 스케줄링

- 짧은 시간 순서대로 프로세스를 수행한다.
- 현재 CPU에서 실행 중인 프로세스의 남은 CPU 버스트 시간보다 더 짧은 CPU 버스트 시간을 가지는 프로세스가 도착하면 CPU가 선점된다.

2) Round Robin 스케줄링

- 시분할 시스템의 성질을 활용한 방법
- 일정 시간을 정하여 하나의 프로세스가 이 시간동안 수행하고 다시 대기 상태로 돌아간다.
- 그리고 다음 프로세스 역시 같은 시간동안 수행한 후, 대기한다. 이러한 작업을 모든 프로세스가 돌아가면서 진행하며, 마지막 프로세스가 끝나면 다시 처음 프로세스로 돌아와서 작업을 반복한다.
- 일정 시간을 Time Quantum(Time Slice)라고 부른다. 일반적으로 10 ~ 100msec 사이의 범위를 갖는다.
- 한 프로세스가 종료되기 전에 time quantum이 끝나면 다른 프로세스에게 CPU를 넘겨주기 때문에 선점형 스케줄링의 대표적인 예시다.

3) Multi-level Queue 스케줄링

- 프로세스를 그룹으로 나누어, 각 그룹에 따라 Ready Queue(준비 큐)를 여러 개 두며, 각 큐마다 다른 규칙을 지정할 수도 있다.(ex. 우선순위, CPU 시간 등)
- 즉, 준비 큐를 여러 개로 분할해 관리하는 스케줄링 방법이다.
- 프로세스들이 CPU를 기다리기 위해 한 줄로 서는 게 아니라 여러 줄로 선다.

![img](https://user-images.githubusercontent.com/34755287/53879673-5e979880-4052-11e9-9f9b-e8bfec7c9be6.png)

4) Multi-level feedback Queue 스케줄링

- 기본 개념은 Multi-level Queue와 동일하나, 프로세스가 하나의 큐에서 다른 큐로 이동 가능하다는 점이 다르다.

![img](https://user-images.githubusercontent.com/34755287/53879675-5f302f00-4052-11e9-86a2-c02ee03bac64.png)

- 위 그림에서 모든 프로세스는 가장 위의 큐에서 CPU의 점유를 대기한다. 이 상태로 진행하다가 이 큐에서 기다리는 시간이 너무 오래 걸린다면 **아래의 큐로 프로세스를 옮긴다.** 이와 같은 방식으로 대기 시간을 조정할 수 있다. 
- 만약, 우선순위 순으로 큐를 사용하는 상황에서 우선순위가 낮은 아래의 큐에 있는 프로세스에서 starvation 상태가 발생하면 이를 우선순위가 높은 위의 큐로 옮길 수도 있다.
- 대부분의 상용 운영체제는 여러 개의 큐를 사용하고 각 큐마다 다른 스케줄링 방식을 사용한다. 프로세스의 성격에 맞는 스케줄링 방식을 사용하여 최대한 효율을 높일 수 있는 방법을 선택한다.



### 비선점형 스케줄링

1) FCFS(First Come First Server)

- 준비 큐에 먼저 도착한 프로세스가 먼저 CPU를 점유하는 방식이다.
- CPU를 할당받으면 CPU 버스트가 완료될 때까지 CPU를 반환하지 않으며, 할당되었던 CPU가 반환될 때만 스케줄링이 이루어진다.

<img src="https://user-images.githubusercontent.com/33534771/89703489-500b8a00-d986-11ea-9b6c-27cca4ea1016.png" width="300" height="300"/>

![img](https://user-images.githubusercontent.com/34755287/53879661-5d666b80-4052-11e9-8453-bad918a563ef.png)

표는 3개의 프로세스와 각 프로세스가 CPU를 사용한 시간(Burst Time)을 나타낸다.

이를 간트 차트로 표현하면 그림과 같다. (도착 시간은 모두 0초라고 가정한다.)

평균 대기 시간은 아래와 같다.

- Average Waiting Time = 0 + 24 + 27 / 3 = 17msec

만약, 프로세스가 들어온 순서가 P3, P2, P1이라면 간트 차트는 아래와 같이 바뀐다.

![img](https://user-images.githubusercontent.com/34755287/53879665-5d666b80-4052-11e9-8ad5-8639b73b13ac.png)

- Average Waiting Time = 3 + 6 + 0 / 3 = 3msec

두 경우에서 모든 프로세스가 끝난 시간은 30msec로 같지만, 평균 대기 시간으로 봤을 때는 위의 예제는 17msec이고 아래는 3msec로 차이가 난다. **즉, 들어온 순서로 수행한다고 해서 반드시 효율적인 것은 아니다.**

위의 예제처럼 `P1, P2, P3` 순서로 들어온 경우를 **Convoy Effect** 라고 한다. 

이는 CPU 시간을 오래 사용하는 프로세스가 먼저 수행되는 동안 나머지 프로세스들은 그만큼 오래 기다리는 것을 뜻한다. P1이 수행되는 동안 P2, P3는 오래 기다리게 된다. 

단점

- Convoy Effect 발생 : 소요 시간이 긴 프로세스가 짧은 프로세스보다 먼저 도착해서 뒤에 프로세스들이 오래 기다려야 하는 현상



2) SJF(Shortest-Job-First)

- 다른 프로세스가 먼저 도착했더라도 CPU 버스트가 짧은 프로세스에게 CPU를 먼저 할당하는 방식이다.
- 선점, 비선점 모두 가능하다.

<img src="https://user-images.githubusercontent.com/33534771/89703540-b7293e80-d986-11ea-9b11-0dabd8e5488f.png" width="300" height="300"/>

![img](https://user-images.githubusercontent.com/34755287/53879666-5d666b80-4052-11e9-93c2-86b725588403.png)

위의 간트 차트는 SJF를 사용했다. 평균 대기 시간은 아래와 같다.

- Average Waiting Time(AWT) = 3 + 9 + 16 + 0 / 4 = 7msec

이번에는 위의 표를 FCSF를 사용해 간트 차트로 나타내고 평균 대기 시간을 구해보자.

![img](https://user-images.githubusercontent.com/34755287/53879667-5d666b80-4052-11e9-8cd4-066aefcf3047.png)

- Average Waiting Time(AWT) = 0 + 6 + 14 + 21 / 4 = 10.25msec

SJF가 평균 대기 시간이 더 짧다. 수학적으로 증명되었으며, 어떠한 예제를 보더라도 SJF의 AWT가 짧다는 것을 알 수 있을 것이다. 



SJF가 가장 효율적인 CPU 스케줄링 방법 같지만, 매우 **비현실적**이다. 왜냐하면 컴퓨터 환경에서는 프로세스의 CPU 점유 시간(Burst time)을 알 수 없다. 한 프로세스가 실행 중에는 많은 변수가 존재하기 때문에 CPU 점유 시간을 알려면 실제로 수행하여 측정하는 수밖에 없다. 실제 측정한 시간으로 예측하여 SJF를 사용할 수도 있지만, 이는 오버헤드가 매우 큰 작업으로 잘 사용되지 않는다.



3) Priority

- 우선순위가 높은 프로세스가 먼저 선택되는 스케줄링 알고리즘이다.
- 우선순위는 정수값으로 나타내며, 작은 값이 우선순위가 높다.(Unix/Linux 기준)

- 선점, 비선점 모두 가능하다.

<img src="https://user-images.githubusercontent.com/33534771/89703556-e344bf80-d986-11ea-87f1-74994cc47510.png" width="300" height="300"/>

![img](https://user-images.githubusercontent.com/34755287/53879671-5e979880-4052-11e9-84d3-524270cdc920.png)

우선순위가 낮은 순서대로 수행한 모습을 간트 차트로 나타냈다.

- Average Waiting Time(AWT) : 0 + 6 + 16 + 18 + 1 / 5 = 8.2msec

우선순위를 정하는 방법은 크게 내부적인 요소와 외부적인 요소로 나뉜다.

- Internal : time limit, memory requirement, I/O to CPU burst(I/O 작업은 길고, CPU 작업은 짧은 프로세스 우선) 등
- External : amout of funds being paid, political factors 등



- 단점 : Starvation(기아) 현상

CPU의 점유를 오랜 시간 동안 하지 못하는 현상을 의미한다. Priority 스케줄링 방식에서 우선순위가 매우 낮은 프로세스가 ready queue에서 대기하고 있다고 가정해보자.

이 프로세스는 아무리 오래 기다려도 CPU를 점유하지 못할 가능성이 매우 크다. 실제 컴퓨터 환경에서는 새로운 프로세스가 자주 ready queue에 들어온다. 이러한 프로세스가 모두 우선순위가 높은 상태라면 이미 기다리고 있던 우선순위가 낮은 프로세스는 하염없이 기다리고만 있는 상태로 남아있을 수 있다. 



이를 해결하는 방법 중 하나는 **aging**이 있다. ready queue에서 기다리는 동안 일정 시간이 지나면 우선 순위를 일정량 높여주는 것이다. 그러면 우선순위가 매우 낮은 프로세스라 하더라도, 기다리는 시간이 길어질수록 우선순위도 계속 높아지므로 수행될 가능성이 커진다.







### Reference

- [운영체제(OS) 6. CPU 스케줄링](https://velog.io/@codemcd/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9COS-6.-CPU-%EC%8A%A4%EC%BC%80%EC%A4%84%EB%A7%81)





### 스케줄러(Scheduler)

- 스케줄링 알고리즘을 알기 전에 스케줄러에 대해 알아보자
- 프로세스들은 자신이 종료될 때까지 수많은 큐들을 돌아다닌다. OS는 이 큐 안에 있는 프로세스 중 하나를 선택해야 하며, 이러한 일을 `스케줄러(Scheduler)`가 담당한다.
- 작업 큐(Job Queue) : 현재 시스템 내의 모든 프로세스의 집합
- 준비 큐(Ready Queue) : 현재 메모리 내에 있으면서 CPU를 할당받고 실행되기 위해 기다리는 프로세스의 집합
- 장치 큐(Device Queue) : 각각의 장치마다 서비스를 기다리며 줄 서 있는 프로세스의 집합





**[장기 스케줄러(Long-term Scheduler)]**

<!-- 메모리는 한정되어 있는데 많은 프로세스들이 한꺼번에 메모리에 올라올 경우, 대용량 메모리(일반적으로 디스크)에 임시로 저장된다. 이 Pool에 저장되어 있는 프로세스 중 어떤 프로세스에 메모리를 할당하여 Ready Queue로 보낼지 결정하는 역할을 한다.
- 메모리와 디스크 사이의 스케줄링을 담당한다.
- 프로세스에 Memory(및 각종 리소스)를 할당한다.(admit)
- degree of Multiprogramming 제어(메모리에 여러 프로그램이 올라가는 것. 즉, 몇 개의 프로그램이 올라갈 것인지를 제어)
- 즉, 디스크와 같은 저장 장치에 작업들을 저장해 놓고 필요할 때 Jab Queue에서 꺼내 Ready Queue에 적재(메모리로 적재)한다.
- 프로세스의 상태 : 시작 상태(New) -> 준비 상태(Ready) -->

- 메모리는 한정되어 있는데 많은 프로세스들이 메모리에 한꺼번에 올라올 경우, 대용량 메모리(디스크)에 임시로 저장한다. 이 Pool(디스크) 내의 저장되어 있는 프로세스 중 어떤 순서로 프로세스를 메모리에 적재할지 결정한다.

- **메모리와 디스크 사이의 스케줄링**을 담당한다. 따라서 상대적으로 호출되는 빈도가 적다.
- 즉, 디스크와 같은 저장 장치에 작업들을 저장해 놓고 필요할 때 실행할 작업을 Job Queue에서 꺼내 Ready Queue를 통해서 메인 메모리에 적재한다.
- degree of Multiprogramming 제어(메모리에 여러 프로그램이 올라가는 것. 즉, 몇 개의 프로그램이 올라갈 것인지를 제어)
- 프로세스의 상태
  - 시작 상태(New) -> 준비 상태(Ready)
  - Running(or Ready) -> Terminated




**[단기 스케줄러(Short-term Scheduler)]**

<!--
- CPU와 메모리 사이의 스케줄링을 담당한다.
- Ready Queue에 존재하는 프로세스 중 어떤 프로세스를 running 시킬지 결정한다.
- 프로세스에 CPU를 할당한다.
- 프로세스의 상태 : ready -> running -> waiting -> ready -->

- **CPU와 메모리 사이의 스케줄링**을 담당한다. 따라서 장기 스케줄러에 비해 매우 많이 호출된다.
- 우선, CPU에게 필요한 데이터를 확보해주고 메모리에 있는 프로세스 중 하나를 선택해서 CPU를 할당한다.
- 즉, Ready Queue에 존재하는 프로세스 중 어떤 프로세스를 running 시킬지 결정한다.
- Ready Queue에 있는 프로세스 중 **먼저 도착한 프로세스에게 CPU를 할당**한다.(=디스페처)
- 프로세스의 상태 : ready -> running -> waiting -> ready



**[중기 스케줄러(Medium-term Scheduler)]**

<!--
- 여유 공간 마련을 위해 프로세스를 통째로 메모리에서 디스크로 쫓아낸다.(Swapping)
- 프로세스에게서 Memory를 deallocate
- degree of Multiprogramming 제어
- 현 시스템에서 메모리에 너무 많은 프로그램이 동시에 올라가는 것을 조절하는 스케줄러
- 프로세스의 상태 : ready -> suspended
-->

- 시분할 시스템에서 추가로 사용하며, 메모리에 대한 가중을 완화시켜주기 위해 중기 스케줄러 도입.
- CPU를 차지하기 위한 경쟁이 심해질 때, 우선순위가 낮은 프로세스들을 잠시 제거한 뒤, 나중에 경쟁이 완화되었을 때 다시 디스크에서 메모리로 불러와 중단되었던 지점부터 실행시킨다. (Swapping)
- 즉, 프로세스들이 서로 CPU를 차지하려고 경쟁이 심해지면 Swapping 기법을 활용하여 메모리를 관리함으로써 너무 많은 프로그램이 동시에 올라가는 것을 조절한다.
- 프로세스의 상태 : ready -> suspended



swap out : 메모리에서 디스크로 잠시 나가는 상태
swap in : 디스크에서 메모리로 다시 들어오는 상태



**[Process state - suspended]**

Suspended(stopped) : 외부적인 이유로 프로세스의 수행이 정지된 상태로 메모리에서 내려간 상태를 의미한다. 프로세스 전부 디스크로 Swap out 된다. 

Blocked 상태는 다른 I/O 작업을 기다리는 상태이기 때문에 스스로 ready state 로 돌아갈 수 있지만, 이 상태는 외부적인 이유로 suspending 되었기 때문에 스스로 돌아갈 수 없다. 



### About 중기 스케줄러

중기 스케줄러에 대해 더 알아보자.

시분할 시스템 운영체제에서는 `중기 스케줄러`를 추가로 도입한다.

Unix나 Window에서는 장기 스케줄러가 거의 사용되지 않는다고 한다. 왜냐하면 일단 작업이 큐에 들어오면 닥치는대로 메모리에 올린다. 물론 OS 자체적인 제한을 두거나 사용자 스스로 제한을 할 수 있도록 하기도 한다.



이를 시분할 시스템에서 어느정도 시스템적으로 완하하기 위해 중기 스케줄러를 도입한 것 같다. 중기 스케줄러를 사용해 **메모리에서 CPU를 쓰기 위해 경쟁하고 있는 프로세스들을 몇 개 제거**한다. 그리고 추후에 **다시 메모리로 불러와서 중단되었던 지점부터 다시 실행을 재게**하게 하는 것이다. -> 스와핑(Swapping) 기법


<img width="682" alt="scheduler2" src="https://user-images.githubusercontent.com/33534771/87003398-82df2880-c1f6-11ea-99da-9deafad24475.png">

<img width="402" alt="scheduler" src="https://user-images.githubusercontent.com/33534771/87003325-604d0f80-c1f6-11ea-9849-589fc4976821.png">


정리하면 중기 스케줄러에 의해 프로세스들이 CPU를 차지하려고 경쟁이 심해지면, `Swap out` 되어 메모리를 떠났다가 다시 `Swap in` 되어 메모리로 돌아온다는 것이다.

<img width="682" alt="scheduler2" src="https://user-images.githubusercontent.com/33534771/87003398-82df2880-c1f6-11ea-99da-9deafad24475.png">


- 작업(Job)이 도착하면 입력 큐(또는 준비 큐)에서 장기 스케줄러에 의해 메모리에 적재된다.
- 단기 스케줄러에 의해 선택되어 CPU를 할당받게 된다.
- Memory Scheduler는 중기 스케줄러의 역할을 하며, 프로세스들이 메모리에서 디스크로 Swap in, Swap out 되는 것을 볼 수 있다.



#### [정리] 장기 스케줄러 vs 단기 스케줄러


`장기 스케줄러와 단기 스케줄러의 가장 큰 차이점은 실행 빈도이다.`

프로세스는 빠르게 실행되고 이러한 프로세스들을 처리하기 위해 즉, 프로세스들 간의 우선순위를 정하기 위해 단기 스케줄러가 동작한다. 여기서 스케줄링의 시간이 지연되면 안되기 때문에 단기 스케줄러는 상당히 빨라야 하고 호출 빈도수가 많다.



그에 반해 시스템에 새로운 작업이 생성되어 들어오는 것은 분 단위로 프로세스의 함수가 실행되는 시간에 비해 무지 길다. 추가로 시스템에서 이탈하는 프로세스도 관리하지만, 장기 스케줄러는 단기 스케줄러보다 호출 빈도수가 매우 적다. 그리고 장기 스케줄링은 스케줄링 시간이 꽤 걸리더라도 신중하게 프로세스를 선택한다. 

만약, 장기 스케줄링이 I/O 프로세스나 CPU 중심 프로세스 중 한쪽으로 편중해서 프로세스를 받아온다면 ready Queue, device Queue 한쪽에 프로세스가 집중되어 버리게 되어 단기 스케줄러의 균형도 붕괴된다.


++ 전체적인 흐름 추가하기(규글)

### Reference

- [OS - 스케줄러의 종류](http://blog.naver.com/PostView.nhn?blogId=4717010&logNo=60208674547)
- [[OS] 스케줄러란?](https://k39335.tistory.com/32)
- [[운영체제] 스케줄러](https://kim6394.tistory.com/177)





## 동기와 비동기

>  동기와 비동기를 비유를 통해 쉽게 설명해보겠다.



해야할 일이 빨래, 설거지, 청소 3가지가 있다고 가정하자. 

- 이 일들을 동기적으로 처리한다면 빨래를 하고 설거지를 한 뒤, 청소를 한다. 
- 비동기적으로 일을 처리한다면 빨래하는 업체에게 빨래를 시킨다. 설거지 대행 업체에 설거지를 시키고, 청소 대행 업체에 청소를 시킨다. 셋 중 어떤 것이 먼저 완료될지는 알 수 없다. 일을 모두 마친 업체는 나에게 알려줄 것이니 나는 다른 작업을 할 수 있다.
  - 이때는 백그라운드 스레드에서 해당 작업을 처리하는 경우의 비동기를 의미한다.



일반적으로 동기와 비동기의 차이는 메소드를 실행시킴과 동시에 반환 값이 기대되는 경우를 **동기**라고 표현하고 그렇지 않은 경우에 대해서 **비동기**라고 표현한다. "동시에"라는 말은 실행되었을 때 값이 반환되기 전까지는 blocking되어 있다는 것을 의미한다. 비동기의 경우, blocking되지 않고 이벤트 큐에 넣거나 백그라운드 스레드에게 해당 task를 위임하고 바로 다음 코드를 실행하기 때문에 기대되는 값이 바로 반환되지 않는다.



> 비유가 아닌 개념적으로 설명해보자.

- 동기(synchronous : 동시에 일어나는)
  - 동시에 일어난다는 뜻이다. 요청과 그 결과가 동시에 일어난다는 약속이다.
  - 바로 요청을 하면 시간이 얼마가 걸리던지 요청한 자리에서 결과가 주어져야 한다.
  - 요청과 결과가 한 자리에서 동시에 일어난다.
  - A노드와 B노드 사이의 작업 처리 단위(transaction)를 동시에 맞추겠다.
- 비동기(Asynchronous : 동시에 일어나지 않는)
  - 동시에 일어나지 않는다를 의미한다. 요청과 결과가 동시에 일어나지 않을 것이라는 약속이다.
  - 요청한 그 자리에서 결과가 주어지지 않는다.
  - 노드 사이의 작업 처리 단위를 동시에 맞추지 않아도 된다.



- 동기 방식은 설계가 매우 간단하고 직관적이지만 결과가 주어질 때까지 아무것도 못하고 대기해야 한다는 단점이 있다.
- 비동기 방식은 동기보다 복잡하지만, 결과가 주어지는데 시간이 걸리더라도 그 시간 동안 다른 작업을 할 수 있으므로 자원을 효율적으로 사용할 수 있다는 장점이 있다.



blocking, non-blocking 글도 참고하기!!

### References

- [[OS] 동기와 비동기](https://k39335.tistory.com/34)
- [동기와 비동기의 개념과 차이](https://private.tistory.com/24)




## Paging vs Segmentation

- 가상 메모리를 관리하는 기법
- `가상 메모리`는 메모리에 로드된 즉, 실행중인 프로세스가 가상의 공간을 참조하여 마치 커다란 물리 메모리를 갖고 있는 것처럼 사용할 수 있도록 하는 것이다.
- 간단하게 말해 **실제 메모리 주소가 아닌 가상의 메모리 주소를 주는 방식**이다.


ex)

내가 실행하고자 하는 프로그램의 용량이 5GB인데, 메모리는 4GB이다. 어떻게 실행할까?

올리는 것도 문제이지만, 올린다고 하더라도 해당 프로그램이 실행될 때는 다른 작업은 아무것도 하지 못하게 된다. 이럴 때, 사용하는 기술이 바로 **가상 메모리**이다.



가상 메모리는 각 프로세스당 메인 메모리와 동일한 크기로 하나씩 할당된다. 그 공간은 보조기억장치 공간을 이용한다. 프로세스의 일부만 메모리에 로드하고 나머지는 보조기억장치에 두는 형태이다.

<img src="https://user-images.githubusercontent.com/33534771/89703730-5995f180-d988-11ea-9864-1870639e4e7a.png" />

이렇게 할당되면 메모리 관리 장치(MMU)에 의해 물리 주소로 변환되어 사용자가 메모리 맵핑이 어떻게 되는지 의식할 필요 없이 알아서 가상 메모리를 활용하여 작업한다.



### 페이징(Paging)

- 프로세스의 주소 공간을 동일한(고정된) 사이즈의 페이지 단위로 나누어 물리적 메모리에 불연속적으로 저장하는 방식
- 외부 단편화와 압축 작업을 해소하기 위함이다.
- 메모리는 `Frame`이라는 고정 크기로 분할되고, 프로세스는 `Page`라 불리는 고정 크기로 분할된다.
- 하나의 프로세스는 연속적인 동작을 수행하는데, 이를 작은 조각으로 나누어 여기저기 흩어진다면 정상적으로 동작할까?
- 이처럼 메모리상에서 여러 곳에 흩어진 프로세스를 수행하기 위해 MMU를 통해 논리 주소와 물리 주소를 나누어 사용함으로써 CPU를 속여야 한다.
- 실제 메모리는 전혀 연속적이지 않는데, CPU는 연속적으로 사용하고 있다는 것을 보장받으며 정상적으로 수행한다.
- 50byte 크기의 프로세스가 있다고 가정하고, 페이징의 크기는 10byte로 나눈다.

![img](https://user-images.githubusercontent.com/34755287/54821888-d9191700-4ce6-11e9-8b11-7af6fdbcbe06.png)

- 프로세스 P1은 5개의 페이지로 나눌 수 있다. 이를 메인 메모리 5곳에 나눠서 할당했다.
- CPU는 논리 주소로 프로그램이 설정한대로 연속적인 주소값으로 명령을 내리고 이는 메모리로 가기 전에 각 페이지의 실제 메모리 주소가 저장되어 있는 **테이블에서 물리 주소로 변경되어야 한다.**
- 프로세스를 나눈 조각을 Page라 하고, 메모리를 나눈 조각을 Frame이라 한다.
- 프로세스는 페이지의 집합이고, 메모리는 프레임의 집합이다.
- 프로세스를 정상적으로 사용하기 위해 MMU의 재배치 레지스터를 여러 개 사용해서 위의 그림과 같이 각 페이지의 실제 주소로 변경해준다. 이러한 여러 개의 재배치 레지스터를 `페이지 테이블(Page Table)`이라 한다.

[단점]

- 내부 단편화 문제의 비중이 늘어나게 된다.
- Ex) Page 크기 : 1024B, 프로세스 A가 3172의 메모리를 요구한다면 3개의 페이지 프레임(1024 x 3 = 3072)을 구성하고도 100B가 남기 때문에 총 4개의 페이지 프레임이 필요하다. 마지막 페이지 프레임에는 924B의 여유 공간이 남게 되는 내부 단편화 문제가 발생한다.



## Advanced!!

### 주소 변환(Address Translation)

페이징 기법을 사용하기 위해서는 여러 개로 흩어진 페이지에 CPU가 접근하기 위해서 페이지 테이블을 통해 주소를 변환해야 한다.

[논리 주소(Logical Address)]

- CPU가 접근하는 주소는 2진수로 표현되고 이는 m비트가 있다고 가정하다. 여기서 하위 n비트는 오프셋(offset) 또는 변위(displacement)라고 한다. 그리고 상위 m-n비트는 페이지의 번호에 해당한다. (n = d, m-n = p)
- 논리주소를 물리주소로 변환하기 위해서 페이지 번호(p)는 페이지 테이블의 인덱스 값이고, p에 해당되는 테이블 내용은 메모리의 프레임 번호이다. 변위(d)는 변하지 않는 값이다. 이 규칙에 대한 예제를 살펴보자.
- Page size = 16bytes
- Page Table = 5,3,2,8,1,4
- 논리 주소 50번지는 물리주소 몇 번지인가?

![img](https://user-images.githubusercontent.com/34755287/54821891-d9191700-4ce6-11e9-98a4-425903e14323.png)

프로세스 P가 메모리에 할당된 모습이다. CPU가 50번지 접근하려고 한다. 그러면 페이지 테이블의 정보를 읽기 위해 논리 주소를 p와 d 값으로 나눠야 한다.

d는 페이지 크기에 따라 달라지는데, 현재 페이지 크기는 16byte이다. 이는 2^4이므로 d = 4이다.

p는 d를 제외한 나머지 크기이다.

그러면 실제로 p,d를 계산해보자. 현재 논리 주소는 50이며, 이진수로 나타내면 110010이다. 먼저, d는 4이므로 이진수의 뒤에서 4칸이 d에 해당된다. d를 제외한 나머지 2칸이 p가 된다.

```
50 = 110010

p = 11

d = 0010
```



p는 이진수 11이고, 십진수로 3이다. 즉, 페이지 테이블의 페이지 번호 3을 가리킨다. 페이지 3번에 해당하는 프레임 번호는 8번이므로, 물리주소를 구성하는 f 값은 8이 된다.

```
f = 1000

d = 0010

물리주소 = 10000010
```

최종적으로 물리주소는 f와 d로 구성되어 있으므로 물리주소는 **이진수로 10000010이 되고, 십진수로 130번지**가 된다. 즉, 변위는 2이므로 8번째 프레임의 시작 주소는 130에서 2를 뺀 128번지(16*8)가 된다.



연속 메모리 할당을 하면서 외부 단편화가 발생하여 이를 해결하기 위해 페이징 기법이 등장했지만, 페이징은 내부 단편화 문제가 발생한다.



### 내부 단편화(Internal Fragment)

내부 단편화는 프로세스 크기가 페이지 크기의 배수가 아닐 경우, 마지막 페이지는 한 프레임(페이지)를 다 채울 수 없어서 발생하는 공간으로 메모리 낭비의 원인이 된다.

예를 들어, 15bytes 크기의 프로세스 p가 있다. 페이지 크기는 4byte로 p를 페이지로 나누면 4,4,4,3의 크기로 총 4개의 페이지가 만들어진다. 마지막 3byte 페이지는 페이지의 크기보다 1byte 작으므로 사용하지 못하고, 이만큼의 메모리 공간이 비게 된다. 이렇게 비어진 공간은 프로세스 p에서도 쓰지 않고, 다른 프로세스에서도 쓰지 못하는 낭비되는 공간이 된다.



아쉽게도 내부 단편화는 해결할 방법이 없다. 하지만, 내부 단편화는 외부 단편화에 비해 낭비되는 메모리 공간은 매우 적다. 내부 단편화의 최대 낭비되는 크기는 page size - 1이 된다. (외부 단편화는 최대 전체 메모리의 1/3이 낭비된다고 한다.) 이는 무시할 정도로 작은 크기이다.



## 보호와 공유

### 보호(Protection)

모든 주소는 페이지 테이블을 경유하므로, 테이블을 이용해서 보호 기능을 수행할 수 있다. 대표적으로 페이지 테이블마다 r(read), w(write), x(execute) 비트를 두어, 해당 비트가 켜져있을 때, 그 수행이 가능하도록 한다.

![img](https://user-images.githubusercontent.com/34755287/57119533-f6410b00-6da5-11e9-884d-00e325b21912.png)

페이지 테이블에 r,w,x 비트를 추가한 모습이다. 만약, 1번 페이지 엔트리처럼 쓰기 비트가 꺼져있는 페이지에 쓰기 작업을 시도하면 CPU에 인터럽트가 발생하여 ISR(Interrupt Service Routine)에서 강제로 해당 프로세스를 종료시킨다.



### 공유(Sharing)

공유는 메모리 낭비를 방지하기 위함이다. 같은 프로그램을 쓰는 복수 개의 프로세스가 있다면, 프로세스의 메모리는 code+data+stack 영역으로 나뉘는데 프로그램이 같다면 code 영역은 같을 것이다. 

그러므로 하나의 code 영역을 복수 개의 프로세스가 공유하여 메모리 낭비를 줄이는 것이다. 단, code가 공유되려면 code가 변하지 않는 프로그램이어야 한다. 이를 **non-self-modifying code = reentrant code(재진입 가능 코드) = puer code** 라고 한다.





### 세그멘테이션(Segmentation)

- 프로세스를 서로 크기가 다른 논리적인 블록 단위인 '세그먼트(Segment)'로 분할하고 메모리에 배치하는 것을 말하며, 각 세그먼트의 크기는 일정하지 않다.
- 프로세스를 Code + Data + Stack 영역으로 나누는 것 역시 세그멘테이션의 모습이다. 물론, code, data, stack 각각 내부에서 더 작은 세그먼트로 나눌 수도 있다.
- 세그먼트를 메모리에 할당할 때는 페이지를 할당하는 것과 동일하다. 하지만, 테이블은 조금 다르다. 세그먼테이션을 위한 테이블은 **세그먼트 테이블**이라고 한다. 
- 세그먼트 테이블은 세그먼트 번호와 시작 주소, 세그먼트 크기를 엔트리로 갖는다. 
- 세그먼트에서 주소변환 역시, 페이징과 유사하다. 한 가지 주의할 점은 세그먼트의 크기는 일정하지 않기 때문에, 테이블에 **limit** 정보가 주어진다. 그리고 CPU에서 해당 세그먼트의 크기를 넘어서는 주소가 들어오면 인터럽트가 발생해서 해당 프로세스를 강제로 종료시킨다. 

![img](https://user-images.githubusercontent.com/34755287/57119448-47043400-6da5-11e9-95da-91cb808de992.png)

위 그림은 세그먼트 테이블과 프로세스가 할당된 메모리의 모습이다. 페이징 주소변환과 동일하게 d(변위 : 변하지 않는 값)는 논리주소와 물리주소가 동일하다. 물리주소 a는 **base[s]+d** 로 계산된다.

- 논리 주소(2, 100) -> 물리주소 4400번지
- 논리 주소(1, 500) -> limit이 400밖에 안되므로 인터럽트로 인해 프로세스 강제 종료(범위를 벗어남)

[단점]

- 외부 단편화 문제가 발생할 수 있다. 



### 세그먼테이션에서 보호와 공유

먼저, 결론부터 말하면 페이징보다 세그먼테이션에서의 보호와 공유는 더 효율적이다. 

보호에서는 세그먼테이션 역시 r,w,x 비트를 테이블에 추가하는데, 세그먼테이션은 논리적으로 나누기 때문에 해당 비트를 설정하기 매우 간단하고 안전하다. 페이징은 code+data+stack 영역이 있을 때, 이를 일정한 크기로 나누므로 두 가지 영역이 섞일 수 있다. 그러면 비트를 설정하기가 매우 까다롭다.



공유에서도 마찬가지다. 페이징에서는 code 영역을 나눈다해도 다른 영역이 포함될 확률이 매우 높다. 하지만, 세그먼테이션은 정확히 code 영역만을 나누기 때문에 더 효율적으로 공유를 수행할 수 있다.



### 세그먼테이션과 페이징

세그먼테이션은 페이징과 유사하고 보호와 공유 측면에서는 더 나은 성능을 보여주었지만, 현재 대부분은 페이징 기법을 사용한다. 그 이유는 세그먼테이션에는 치명적인 단점이 존재하기 때문이다.

메모리 할당을 처음 시작할 때, 다중 프로그래밍에서의 문제는 크기가 서로 다른 프로세스로 인해 여러 크기의 hole이 발생한다. 이로 인해 어느 hole에 프로세스를 할당하는 것에 대한 최적화 알고리즘이 존재하지 않고, 외부 단편화로 인해 메모리 낭비가 크다고 했었다.

세그먼테이션도 똑같은 문제점이 발생한다. 왜냐하면 세그먼테이션은 논리적인 단위로 나누기 때문에 세그먼트의 **크기가 다양하다.** 이로 인해 다양한 크기의 hole이 발생하므로 같은 문제가 발생한다.

결론적으로 세그먼테이션은 보호와 공유에서 효율적이고, 페이징은 외부 단편화 문제를 해결할 수 있다. 그러므로 이 두가지를 합쳐서 사용하는 방법이 나왔다. 두 장점을 합치기 위해서는 **세그먼트를 페이징 기법으로 나누는 것이다. (Paged Segmentation)**

하지만, 이 역시 단점이 존재한다. 세그먼트와 페이지가 동시에 존재하기 때문에 주소 변환도 두번해야 한다. 즉, CPU에서 세그먼트 테이블에서 주소 변환을 하고, 그 다음 페이지 테이블에서 또 주소 변환을 해야 한다.



### Reference

- [운영체제 13. 페이징](https://velog.io/@codemcd/운영체제OS-13.-페이징)
- [운영체제 14. 세그멘테이션](https://velog.io/@codemcd/운영체제OS-14.-세그멘테이션)
- [세그멘테이션과 페이징](https://m.blog.naver.com/s2kiess/220149980093)




### 페이지 교체 알고리즘



- 가상 메모리는 `요구 페이징 기법`을 통해 필요한 페이지만 메모리에 적재하고 사용하지 않는 부분은 그대로 둔다.
- 하지만, 필요한 페이지만 올리더라도 메모리는 결국 가득 차게 되고, 올라와있던 페이지가 사용이 다 된 후에도 자리만 차지하고 있을 수 있다.
- 메모리가 가득차면, 추가로 페이지를 가져오기 위해서 안쓰는 페이지는 out하고 해당 공간에 현재 필요한 페이지를 in 시켜야 한다. 이때, 어떤 페이지를 out 시킬지 정해야 한다. 
- 수정이 되지 않는 페이지를 선택해야 좋다. 만약, 수정되면 메인 메모리에서 내보낼 때, 하드디스크에서 또 수정해야 하므로 시간이 오래걸린다.
- 이러한 상황에서 적절한 페이지 교체를 위해 페이지 교체 알고리즘이 존재한다.



### 가상 메모리

- 운영체제는 모든 프로그램에게 같은 크기의 메모리를 할당하지 않고 몇몇 프로그램에게 집중적으로 메모리를 할당한 후, 시간이 흐르면 이들에게서 메모리를 회수하여 다른 프로그램들에게 다시 집중적으로 할당하는 방식을 사용한다.
- CPU를 할당받아 당장 수행해야 할 부분만 메모리에 올려놓고 그렇지 않은 부분은 디스크의 스왑 영역에 내려놓았다가 다시 필요해지만 메모리에 올라가 있는 부분과 교체하는 방식을 사용한다. 이를 통해 프로그램이 자기 자신만 메모리를 사용하는 것과 같은 효과를 낸다.
- 가상 메모리는 프로세스마다 각각 0번지부터 시작하는 자기 자신만의 주소 공간을 가지게 되며, 이들 공간 중 일부는 물리적 메모리에 적재되고 일부는 디스크의 스왑 영역에 적재된다. -> **요구 페이징 기법**



**[요구 페이징]**

- 가상 메모리는 요구 페이징 기법을 통해 필요한 페이지만 메모리에 적재하고 사용하지 않는 부분은 그대로 둔다.
- 특정 페이지에 대해 CPU의 요청이 들어온 후에야 해당 페이지를 메모리에 적재하며, 한번도 접근되지 않은 페이지는 물리적 메모리에 적재되지 않는다.
- 이를 통해 메모리 사용량이 감소하고 프로세스 전체를 메모리에 올리는데 들었던 입출력 오버헤드가 감소하며 응답시간이 단축된다.
- 유효, 무효 비트를 두어 각 페이지가 메모리에 존재하는지 표시한다.
  - 유효 : 페이지가 메모리에 적재됨.
  - 무효 : 페이지가 현재 메모리에 없는 경우이거나 그 페이지가 속한 주소 영역을 프로세스가 사용하지 않는 경우
- CPU가 참조하려는 페이지가 현재 메모리에 올라와 있지 않아 **무효**로 세팅되어 있는 경우를 `'페이지 부재'`가 일어났다고 한다.



**[페이지 교체]**

- 페이지 부재가 발생하면 요청된 페이지를 디스크에서 메모리로 읽어와야 한다. 이때 물리적 메모리에 빈 프레임이 존재하지 않을 수 있다.
- 이 경우, 메모리에 올라와있는 페이지 중 하나를 디스크로 쫓아내고 메모리에 빈 공간을 확보하는 작업이 필요하다. 이를 페이지 교체라고 한다.
- 페이지 교체를 할 때, 어떤 프레임에 있는 페이지를 쫓아낼 것인지 결정하는 알고리즘을 페이지 교체 알고리즘이라 하며, 목표는 페이지 부재율을 최소화하는 것이다. 

<u>*페이지 부재 발생 -> 새로운 페이지를 할당해야 한다. -> 현재 할당된 페이지(메모리에 올라와있는 페이지) 중 어떤 것을 교체할지 결정하는 방법*</u>



### 페이지 교체 알고리즘

1) FIFO(First in First out) 알고리즘

- 페이지 교체시 메모리에 먼저 올라온 페이지를 먼저 내보내는 알고리즘
- 가장 간단한 방법으로, 특히 초기화 코드에서 적절한 방법이다. 
- 단점
  - 페이지의 향후 참조 가능성을 고려하지 않고, 물리적 메모리에 들어온 순서대로 내쫓을 대상을 선정하기 때문에 비효율적인 상황이 발생할 수 있다.
  - 빌레이디의 모순 현상이 발생할 수 있다. (페이지 프레임 수가 많으면(메모리 증가) 페이지 부재수가 줄어드는 것이 일반적이지만, 페이지 프레임 수를 증가시켰음에도 페이지 부재가 더 많이 일어나는 현상을 의미한다.)

![img](https://camo.githubusercontent.com/250c0a33495ccda3dcaaa1c2b4d79ec22bf07da3/68747470733a2f2f696d67312e6461756d63646e2e6e65742f7468756d622f523132383078302f3f73636f64653d6d746973746f727926666e616d653d68747470732533412532462532466b2e6b616b616f63646e2e6e6574253246646e253246565143474b253246627471754a7571526b79532532464c62334e6777486b427665303859685a704c6b713331253246696d672e706e67)



2) 최적 페이지 교체 알고리즘(Optimal Page Replacement)

- 앞으로 가장 오랫동안 사용하지 않은 페이지를 교체하는 방법
- 미래에 어떤 페이지가 어떠한 순서로 참조될지 미리 알고있다는 전제하에 알고리즘을 운영하므로 현실적으로 구현이 어렵다.
- 페이지 부재율이 가장 낮은 효율적인 알고리즘이다.

![img](https://t1.daumcdn.net/cfile/tistory/265B26335916A03F39)



3) LRU 알고리즘(Least Recently Used)

- 최근에 사용하지 않은 페이지를 가장 먼저 내보내는 방법
- 최근에 사용하지 않았으면, 나중에도 사용되지 않을 것이라는 아이디어에서 나왔다.
- OPT의 경우 미래 예측이지만, LRU의 경우는 과거를 보고 판단하므로 실질적으로 사용이 가능한 알고리즘 (실제로도 최근에 사용하지 않은 페이지는 앞으로도 사용하지 않을 확률이 높다.)
- OPT보다는 페이지 결함이 더 일어날 수 있지만, **실제로 사용할 수 있는 페이지 교체 알고리즘에서는 가장 좋은 방법 중 하나이다.**

![img](https://camo.githubusercontent.com/3da1359d56b8c12c4da96d937554b8375d0cac1f/68747470733a2f2f696d67312e6461756d63646e2e6e65742f7468756d622f523132383078302f3f73636f64653d6d746973746f727926666e616d653d68747470732533412532462532466b2e6b616b616f63646e2e6e6574253246646e2532466e43676333253246627471754757395655726d25324678544b6e564b504f56517553586d4175526568537731253246696d672e706e67)



4) LFU 알고리즘(Least Frequently Used) 

- 페이지의 참조 횟수로 교체할 페이지를 결정하는 방법
- 즉, 물리적 메모리 내에 존재하는 페이지 중에서 과거에 참조 횟수가 가장 적었던 페이지를 내쫓고 그 자리에 새로 참조될 페이지를 적재한다.
- 단점
  - 시간에 따른 페이지 참조의 변화를 반영하지 못하고 LRU보다 구현이 복잡하다.

- LRU, LFU 알고리즘은 페이지의 최근 참조 시각 및 참조 횟수를 소프트웨어적으로 유지해야 하므로 알고리즘의 운영에 오버헤드가 발생한다.

5) 클럭 알고리즘(NRU : Not Recently Used, NUR : Not Used Recently)

- 하드웨어적인 지원을 받아 LRU와 LFU 알고리즘에서 발생한 시간적인 오버헤드를 줄인 방식이다.
- LRU를 근사시킨 알고리즘이라고 하며, 오랫동안 사용하지 않은 페이지 중 하나를 교체한다.
- 최근에 참조되지 않은 페이지를 교체 대상으로 선정하는 측면에서 LRU와 비슷하지만 교체되는 페이지의 참조 시점이 가장 오래됐다는 것을 보장하지 못한다.
- 참조 비트(Reference Bit)와 변형 비트(Modified Bit, Dirty Bit)를 사용한다.
  - 참조 비트
    - 페이지가 참조될 때, 1로 자동 세팅된다. 
    - 페이지가 참조되지 않았을 때는 0이 되며 페이지는 교체한다.
  - 변형 비트
    - 페이지 내용이 변경되었을 때, 1로 지정한다.
    - 페이지 내용이 변경되지 않았을 때는 0으로 지정한다.

- 이 알고리즘은 하드웨어의 자원으로 동작하기 때문에 LRU에 비해 교체 페이지의 선정이 훨씬 빠르게 결정된다.
- 따라서 대부분의 시스템에서 페이지 교체 알고리즘으로 클럭 알고리즘을 채택한다.



### Reference

- [가상메모리-02-페이지 교체 알고리즘](https://eunhyejung.github.io/os/2018/07/24/operatingsystem-study15.html)
- [규글님 - 페이지 교체 알고리즘](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Operation%20System/Page%20Replacement%20Algorithm.md)



### 단편화

**[외부 단편화(external fragmentation)]**

- 프로그램의 크기보다 분할의 크기가 작은 경우, 해당 분할이 비어있음에도 불구하고 프로그램을 적재하지 못하기 때문에 발생하는 메모리 공간을 말한다.
- 어떤 프로그램에도 배당되지 않은 빈 공간임에도 현재 상태에서 사용될 수 없는 작은 분할이다.



**[내부 단편화(internal fragmentation)]**

- 프로그램의 크기보다 분할의 크기가 큰 경우, 해당 분할에 프로그램을 적재하고 남는 메모리 공간을 말한다.
- 즉, 하나의 분할 내부에서 발생하는 사용되지 않는 메모리 조각이다.
- ex) 메모리 자유 분할 공간이 10,000B가 있고 프로세스 A가 9,999B를 사용하게 되면 2B가 남게 된다. 이러한 현상을 내부 단편화라 한다.



**[압축(Compaction)]**

- 외부 단편화를 해소하기 위해 프로세스가 사용하는 공간들을 한쪽으로 몰아, 자유 공간을 확보하는 방법론이다.
- 단점 : 작업 효율이 좋지 않다.



**[Swapping]**

- 메모리에 올라온 프로세스의 주소 공간 전체를 디스크의 스왑 영역으로 일시적으로 내려놓는 것이다. 메모리 공간을 확보하면 이후에 다른 프로세스의 메모리를 불러 들일 수 있다.
- 주의할 점은 프로세스가 종료되어 주소 공간을 디스크로 내쫓는 것이 아니라 특정한 이유로 수행중인 프로세스의 주소공간을 일시적으로 메모리에서 디스크로 내려놓은 것을 의미한다.
  - 스왑인 : 디스크 -> 메모리
  - 스왑 아웃 : 메모리 -> 디스크



**[연속 할당 방식]**

- 각각의 프로세스를 물리적 메모리의 연속적인 공간에 올리는 방식
  1. 고정 분할 방식
     - 물리적 메모리를 주어진 개수만큼의 영구적인 분할로 미리 나누고 각 분할에 하나의 프로세스를 적재하여 실행시키는 방식
     - 단편화 문제 발생
  2. 가변 분할 방식
     - 메모리에 적재되는 프로그램의 크기에 따라 분할의 크기, 개수가 동적으로 변하는 방식
     - 외부 단편화 발생



**[불연속 할당 방식]**

- 하나의 프로세스를 물리적 메모리의 여러 영역에 분산하여 적재하는 방식
  1. 페이징 
     - 프로세스를 동일한 크기의 페이지로 나눈다.
     - 내부 단편화 문제
  2. 세그멘테이션
     - 프로세스를 서로 다른 크기의 논리적 블록 단위인 세그멘테이션으로 나눈다.
     - 외부 단편화 문제





     ### IPC(Inter Process Communication)

![img](https://camo.githubusercontent.com/39947826ff6c0138a468fd6a5d7cb5ee70737397/68747470733a2f2f74312e6461756d63646e2e6e65742f6366696c652f746973746f72792f393944423843343935433443353730343137)

- 프로세스는 독립적으로 실행된다. 이는 다른 프로세스에게 영향을 받지 않는다는 뜻이기도 하다. (스레드는 프로세스 안에서 자원을 공유하므로 영향을 받는다.)

- 이처럼 독립적인 공간을 가진 프로세스간 통신에 사용되는 기법이 IPC 통신이다.
- 프로세스는 커널이 제공하는 IPC 설비를 이용해 프로세스간 통신을 할 수 있게 된다.




### Reference

- [규글님 - IPC](https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Operation%20System/IPC(Inter%20Process%20Communication).md)